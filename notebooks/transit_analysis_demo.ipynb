{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TransitVision: Transit Data Analysis and Prediction\n",
    "\n",
    "This notebook demonstrates the key functionality of the TransitVision package for analyzing transit data and making predictions about ridership patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration\n",
    "\n",
    "First, let's import the necessary modules and set up the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transitvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Import TransitVision modules\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransitvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_processing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransit_data_processor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransitDataProcessor\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransitvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_processing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeedback_processor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FeedbackProcessor\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransitvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manalysis\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransit_analyzer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TransitAnalyzer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transitvision'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Import TransitVision modules\n",
    "from transitvision.data_processing.transit_data_processor import TransitDataProcessor\n",
    "from transitvision.data_processing.feedback_processor import FeedbackProcessor\n",
    "from transitvision.analysis.transit_analyzer import TransitAnalyzer\n",
    "from transitvision.analysis.sentiment_analyzer import SentimentAnalyzer\n",
    "from transitvision.prediction.ridership_model import RidershipModel\n",
    "from transitvision.prediction.remote_work_impact import RemoteWorkImpactModel\n",
    "from transitvision.utils.logger import setup_logger\n",
    "from transitvision.utils.data_utils import load_data, save_data\n",
    "from transitvision.utils.visualization import set_plot_style\n",
    "\n",
    "# Set up logger\n",
    "logger = setup_logger(level=\"INFO\", console=True)\n",
    "\n",
    "# Set visualization style\n",
    "set_plot_style(style=\"whitegrid\", context=\"notebook\", palette=\"viridis\")\n",
    "\n",
    "# Display settings\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Sample Data\n",
    "\n",
    "For this demonstration, we'll generate synthetic transit data to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transit_data(n_days=90, n_routes=5, n_stops_per_route=10, seed=42):\n",
    "    \"\"\"Generate synthetic transit data for demonstration.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Generate dates\n",
    "    start_date = pd.Timestamp('2023-01-01')\n",
    "    dates = [start_date + pd.Timedelta(days=i) for i in range(n_days)]\n",
    "    \n",
    "    # Generate routes and stops\n",
    "    routes = [f\"Route_{i}\" for i in range(1, n_routes + 1)]\n",
    "    stops = [f\"Stop_{i}\" for i in range(1, n_stops_per_route + 1)]\n",
    "    \n",
    "    # Create base dataframe structure\n",
    "    data = []\n",
    "    \n",
    "    for date in dates:\n",
    "        # Weekend modifier for ridership\n",
    "        is_weekend = date.dayofweek >= 5\n",
    "        weekend_factor = 0.7 if is_weekend else 1.0\n",
    "        \n",
    "        # Monthly seasonality (higher in summer)\n",
    "        month = date.month\n",
    "        monthly_factor = 1.0 + 0.2 * np.sin((month - 1) * np.pi / 6)\n",
    "        \n",
    "        # Weather effect (random daily factor)\n",
    "        weather_factor = np.random.uniform(0.8, 1.2)\n",
    "        \n",
    "        # Remote work percentage (gradually increasing over time)\n",
    "        day_index = (date - start_date).days\n",
    "        remote_work_pct = 20 + 10 * (day_index / n_days)\n",
    "        \n",
    "        for route in routes:\n",
    "            # Route-specific factors\n",
    "            route_idx = int(route.split('_')[1])\n",
    "            route_factor = 0.8 + 0.1 * route_idx\n",
    "            \n",
    "            for stop in stops:\n",
    "                # Stop-specific factors\n",
    "                stop_idx = int(stop.split('_')[1])\n",
    "                stop_factor = 0.9 + 0.02 * stop_idx\n",
    "                \n",
    "                # Calculate base ridership\n",
    "                base_ridership = 100 * route_factor * stop_factor\n",
    "                \n",
    "                # Apply modifiers\n",
    "                ridership = base_ridership * weekend_factor * monthly_factor * weather_factor\n",
    "                \n",
    "                # Apply remote work effect (more impact on commuter routes)\n",
    "                remote_work_impact = 1.0 - (0.01 * remote_work_pct * route_factor)\n",
    "                ridership = ridership * remote_work_impact\n",
    "                \n",
    "                # Add some random noise\n",
    "                ridership = max(0, int(ridership * np.random.normal(1, 0.1)))\n",
    "                \n",
    "                # Generate capacity (somewhat correlated with ridership)\n",
    "                capacity = int(max(ridership * 1.5, 150) * np.random.uniform(0.9, 1.1))\n",
    "                \n",
    "                # Generate delay (correlated with ridership/capacity ratio)\n",
    "                utilization = ridership / capacity\n",
    "                delay_base = 2 * utilization * np.random.exponential(1)\n",
    "                delay = round(max(0, delay_base), 1)\n",
    "                \n",
    "                # Create data point\n",
    "                data.append({\n",
    "                    'service_date': date,\n",
    "                    'route_id': route,\n",
    "                    'stop_id': stop,\n",
    "                    'ridership': ridership,\n",
    "                    'capacity': capacity,\n",
    "                    'delay': delay,\n",
    "                    'temperature': round(20 + 10 * np.sin((date.dayofweek - 1) * np.pi / 7) + np.random.normal(0, 3), 1),\n",
    "                    'precipitation': max(0, round(np.random.exponential(0.5), 2)),\n",
    "                    'is_holiday': date.dayofweek >= 5 or np.random.random() < 0.05,\n",
    "                    'remote_work_percent': round(remote_work_pct, 1),\n",
    "                })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Add time features\n",
    "    df['service_month'] = df['service_date'].dt.month\n",
    "    df['service_day'] = df['service_date'].dt.day\n",
    "    df['service_dayofweek'] = df['service_date'].dt.dayofweek\n",
    "    df['is_weekend'] = df['service_dayofweek'] >= 5\n",
    "    \n",
    "    return df\n",
    "\n",
    "def generate_feedback_data(transit_data, n_feedback=500, seed=42):\n",
    "    \"\"\"Generate synthetic feedback data based on transit data.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Sample from transit data to get realistic dates and routes\n",
    "    sampled_data = transit_data.sample(n=n_feedback, random_state=seed)\n",
    "    \n",
    "    # Positive feedback templates\n",
    "    positive_templates = [\n",
    "        \"The {route} was on time and clean. Very satisfied with the service.\",\n",
    "        \"Driver was friendly and helpful. {route} was punctual as always.\",\n",
    "        \"Great experience on {route} today. Comfortable ride and efficient service.\",\n",
    "        \"Love the new schedule for {route}, makes my commute much easier.\",\n",
    "        \"The bus was clean and not crowded. Very pleasant ride on {route}.\",\n",
    "        \"Excellent service on {route} this morning. Right on schedule!\",\n",
    "        \"The {route} driver was very professional and courteous.\",\n",
    "        \"I appreciate the reliability of {route}. Always a good experience.\"\n",
    "    ]\n",
    "    \n",
    "    # Negative feedback templates\n",
    "    negative_templates = [\n",
    "        \"The {route} was late again. Very frustrating for daily commuters.\",\n",
    "        \"Bus was overcrowded and uncomfortable. {route} needs more frequent service.\",\n",
    "        \"Driver was rude and unhelpful. Poor experience on {route} today.\",\n",
    "        \"The {route} was dirty and had a bad smell. Please improve cleaning.\",\n",
    "        \"Disappointed with {route} service. Too many delays and no communication.\",\n",
    "        \"The air conditioning wasn't working on {route}. Terrible experience in this heat.\",\n",
    "        \"Why is {route} always late? Need better schedule adherence.\",\n",
    "        \"The {route} bus broke down mid-journey. Needs better maintenance.\"\n",
    "    ]\n",
    "    \n",
    "    # Neutral feedback templates\n",
    "    neutral_templates = [\n",
    "        \"Average experience on {route}. Nothing special to report.\",\n",
    "        \"The {route} was slightly delayed but overall okay.\",\n",
    "        \"Regular service on {route} today. No issues to mention.\",\n",
    "        \"Standard experience on {route}. Could use some minor improvements.\",\n",
    "        \"The {route} was adequate for my needs today.\",\n",
    "        \"Typical journey on {route}. Neither good nor bad.\",\n",
    "        \"The {route} was moderately crowded but manageable.\",\n",
    "        \"Satisfactory service on {route}, though there's room for improvement.\"\n",
    "    ]\n",
    "    \n",
    "    # Generate feedback\n",
    "    data = []\n",
    "    \n",
    "    for _, row in sampled_data.iterrows():\n",
    "        # Determine sentiment based on delay and ridership/capacity ratio\n",
    "        delay = row['delay']\n",
    "        utilization = row['ridership'] / row['capacity']\n",
    "        \n",
    "        # Calculate base sentiment score (-1 to 1)\n",
    "        sentiment_score = 0.5 - (delay / 15) - (utilization - 0.5)\n",
    "        sentiment_score += np.random.normal(0, 0.3)  # Add noise\n",
    "        \n",
    "        # Determine sentiment category\n",
    "        if sentiment_score > 0.3:\n",
    "            sentiment = \"positive\"\n",
    "            rating = np.random.choice([4, 5], p=[0.3, 0.7])\n",
    "            template = np.random.choice(positive_templates)\n",
    "        elif sentiment_score < -0.3:\n",
    "            sentiment = \"negative\"\n",
    "            rating = np.random.choice([1, 2], p=[0.7, 0.3])\n",
    "            template = np.random.choice(negative_templates)\n",
    "        else:\n",
    "            sentiment = \"neutral\"\n",
    "            rating = np.random.choice([3, 4], p=[0.7, 0.3])\n",
    "            template = np.random.choice(neutral_templates)\n",
    "        \n",
    "        # Format feedback text\n",
    "        feedback_text = template.format(route=row['route_id'])\n",
    "        \n",
    "        # Add some typos or variations (10% chance per feedback)\n",
    "        if np.random.random() < 0.1:\n",
    "            words = feedback_text.split()\n",
    "            if len(words) > 3:\n",
    "                word_idx = np.random.randint(0, len(words))\n",
    "                if len(words[word_idx]) > 3:\n",
    "                    char_idx = np.random.randint(1, len(words[word_idx]) - 1)\n",
    "                    word_list = list(words[word_idx])\n",
    "                    word_list[char_idx] = np.random.choice(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "                    words[word_idx] = ''.join(word_list)\n",
    "                    feedback_text = ' '.join(words)\n",
    "        \n",
    "        # Create feedback entry\n",
    "        data.append({\n",
    "            'feedback_text': feedback_text,\n",
    "            'feedback_date': row['service_date'],\n",
    "            'route_id': row['route_id'],\n",
    "            'stop_id': row['stop_id'],\n",
    "            'rating': rating,\n",
    "            'sentiment': sentiment\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate the datasets\n",
    "transit_data = generate_transit_data()\n",
    "feedback_data = generate_feedback_data(transit_data)\n",
    "\n",
    "# Display sample data\n",
    "print(f\"Transit data shape: {transit_data.shape}\")\n",
    "print(f\"Feedback data shape: {feedback_data.shape}\")\n",
    "\n",
    "transit_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing\n",
    "\n",
    "Let's process the transit data using our data processing modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transit data processor\n",
    "transit_processor = TransitDataProcessor(\n",
    "    config={\n",
    "        \"time_columns\": [],\n",
    "        \"categorical_columns\": [\"route_id\", \"stop_id\"],\n",
    "        \"numerical_columns\": [\"ridership\", \"capacity\", \"delay\", \"temperature\", \"precipitation\", \"remote_work_percent\"],\n",
    "        \"date_columns\": [\"service_date\"],\n",
    "        \"drop_na_columns\": [\"route_id\", \"stop_id\", \"ridership\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "# Process the transit data\n",
    "processed_transit_data = transit_processor.process_data(transit_data)\n",
    "\n",
    "# Display the processed data\n",
    "print(f\"Processed transit data shape: {processed_transit_data.shape}\")\n",
    "processed_transit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create feedback processor\n",
    "feedback_processor = FeedbackProcessor(\n",
    "    config={\n",
    "        \"text_column\": \"feedback_text\",\n",
    "        \"date_column\": \"feedback_date\",\n",
    "        \"rating_column\": \"rating\",\n",
    "        \"route_column\": \"route_id\",\n",
    "        \"min_feedback_length\": 5\n",
    "    }\n",
    ")\n",
    "\n",
    "# Process the feedback data\n",
    "processed_feedback_data = feedback_processor.process_data(feedback_data)\n",
    "\n",
    "# Display the processed data\n",
    "print(f\"Processed feedback data shape: {processed_feedback_data.shape}\")\n",
    "processed_feedback_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transit Data Analysis\n",
    "\n",
    "Now let's analyze the transit data to extract insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transit analyzer\n",
    "transit_analyzer = TransitAnalyzer(\n",
    "    config={\n",
    "        \"date_column\": \"service_date\",\n",
    "        \"route_column\": \"route_id\",\n",
    "        \"stop_column\": \"stop_id\",\n",
    "        \"ridership_column\": \"ridership\",\n",
    "        \"capacity_column\": \"capacity\",\n",
    "        \"delay_column\": \"delay\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Analyze ridership patterns over time\n",
    "ridership_patterns = transit_analyzer.analyze_ridership_patterns(\n",
    "    data=processed_transit_data,\n",
    "    time_grouping=\"daily\"\n",
    ")\n",
    "\n",
    "# Plot ridership trends\n",
    "transit_analyzer.plot_ridership_trends(\n",
    "    data=processed_transit_data,\n",
    "    time_grouping=\"daily\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare routes by ridership\n",
    "route_comparison = transit_analyzer.compare_routes(\n",
    "    data=processed_transit_data,\n",
    "    metric=\"ridership\",\n",
    "    time_period=\"weekly\"\n",
    ")\n",
    "\n",
    "# Plot route comparison\n",
    "transit_analyzer.plot_performance_comparison(\n",
    "    data=processed_transit_data,\n",
    "    metric=\"ridership\",\n",
    "    plot_type=\"boxplot\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze performance metrics (delay)\n",
    "delay_analysis = transit_analyzer.analyze_performance_metrics(\n",
    "    data=processed_transit_data,\n",
    "    metric=\"delay\"\n",
    ")\n",
    "\n",
    "# Plot delay comparison\n",
    "transit_analyzer.plot_performance_comparison(\n",
    "    data=processed_transit_data,\n",
    "    metric=\"delay\",\n",
    "    plot_type=\"violin\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis\n",
    "\n",
    "Let's analyze the sentiment in the rider feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentiment analyzer\n",
    "sentiment_analyzer = SentimentAnalyzer(\n",
    "    config={\n",
    "        \"text_column\": \"feedback_text\",\n",
    "        \"date_column\": \"feedback_date\",\n",
    "        \"rating_column\": \"rating\",\n",
    "        \"route_column\": \"route_id\",\n",
    "        \"topic_extraction_method\": \"keyword\",\n",
    "        \"num_topics\": 5\n",
    "    }\n",
    ")\n",
    "\n",
    "# Analyze sentiment\n",
    "sentiment_results = sentiment_analyzer.analyze_sentiment(processed_feedback_data)\n",
    "\n",
    "# Extract topics\n",
    "topic_results, topics = sentiment_analyzer.extract_topics(sentiment_results)\n",
    "\n",
    "# Plot sentiment distribution\n",
    "sentiment_analyzer.plot_sentiment_distribution(sentiment_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment distribution by route\n",
    "sentiment_analyzer.plot_sentiment_distribution(\n",
    "    data=sentiment_results,\n",
    "    groupby=\"route_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sentiment trends over time\n",
    "sentiment_analyzer.plot_sentiment_over_time(\n",
    "    data=sentiment_results,\n",
    "    time_grouping=\"weekly\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot topic distribution\n",
    "sentiment_analyzer.plot_topic_distribution(\n",
    "    data=topic_results,\n",
    "    topics=topics\n",
    ")\n",
    "\n",
    "# Print extracted topics\n",
    "print(\"Extracted Topics:\")\n",
    "for sentiment, keywords in topics.items():\n",
    "    print(f\"\\n{sentiment.capitalize()} sentiment topics:\")\n",
    "    for i, keyword in enumerate(keywords, 1):\n",
    "        print(f\"  {i}. {keyword}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridership Prediction\n",
    "\n",
    "Now let's build a model to predict transit ridership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Select features and target\n",
    "features = [\n",
    "    'service_month', 'service_day', 'service_dayofweek', 'is_weekend',\n",
    "    'temperature', 'precipitation', 'is_holiday', 'remote_work_percent'\n",
    "]\n",
    "\n",
    "# Add route and stop dummy variables\n",
    "route_dummies = pd.get_dummies(processed_transit_data['route_id'], prefix='route')\n",
    "stop_dummies = pd.get_dummies(processed_transit_data['stop_id'], prefix='stop')\n",
    "\n",
    "# Combine features\n",
    "X = pd.concat([processed_transit_data[features], route_dummies, stop_dummies], axis=1)\n",
    "y = processed_transit_data['ridership']\n",
    "\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create ridership model\n",
    "ridership_model = RidershipModel(\n",
    "    model_type=\"random_forest\",\n",
    "    model_params={\n",
    "        \"n_estimators\": 100,\n",
    "        \"max_depth\": 15,\n",
    "        \"min_samples_split\": 5,\n",
    "        \"random_state\": 42\n",
    "    },\n",
    "    scale_features=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "ridership_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluation = ridership_model.evaluate(X_test, y_test, plot=True)\n",
    "\n",
    "# Print evaluation metrics\n",
    "for metric, value in evaluation.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "# Extract a route for visualization\n",
    "route_to_plot = 'Route_1'\n",
    "stop_to_plot = 'Stop_1'\n",
    "\n",
    "mask = (\n",
    "    (processed_transit_data['route_id'] == route_to_plot) & \n",
    "    (processed_transit_data['stop_id'] == stop_to_plot)\n",
    ")\n",
    "\n",
    "route_data = processed_transit_data[mask].sort_values('service_date')\n",
    "route_features = X[mask].reset_index(drop=True)\n",
    "route_ridership = y[mask].reset_index(drop=True)\n",
    "\n",
    "# Plot actual vs predicted\n",
    "ridership_model.plot_predictions(\n",
    "    route_features,\n",
    "    route_ridership,\n",
    "    time_column=route_data['service_date'].reset_index(drop=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = ridership_model.get_feature_importance()\n",
    "\n",
    "# Plot top 20 features\n",
    "ridership_model.plot_feature_importance(\n",
    "    importance=feature_importance['importance'].values,\n",
    "    feature_names=feature_importance['feature'].values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remote Work Impact Analysis\n",
    "\n",
    "Let's analyze how remote work patterns affect transit ridership."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create remote work impact model\n",
    "remote_work_model = RemoteWorkImpactModel(\n",
    "    model_type=\"elastic_net\",\n",
    "    model_params={\n",
    "        \"alpha\": 0.1,\n",
    "        \"l1_ratio\": 0.5,\n",
    "        \"random_state\": 42\n",
    "    },\n",
    "    remote_work_column=\"remote_work_percent\",\n",
    "    time_features=['service_month', 'service_day', 'service_dayofweek']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "remote_work_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "remote_work_evaluation = remote_work_model.evaluate(X_test, y_test, plot=True)\n",
    "\n",
    "# Print evaluation metrics\n",
    "for metric, value in remote_work_evaluation.items():\n",
    "    print(f\"{metric}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform sensitivity analysis\n",
    "sensitivity_results = remote_work_model.sensitivity_analysis(\n",
    "    X=X_test.iloc[:1],  # Use first test sample as baseline\n",
    "    remote_work_values=[0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100],\n",
    "    feature_values={\n",
    "        \"is_weekend\": [0, 1],  # Test both weekday and weekend\n",
    "        \"is_holiday\": [0, 1]   # Test both regular day and holiday\n",
    "    }\n",
    ")\n",
    "\n",
    "# Plot impact of remote work\n",
    "remote_work_model.plot_remote_work_impact(\n",
    "    sensitivity_results=sensitivity_results,\n",
    "    group_by=\"is_weekend\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define scenarios\n",
    "scenarios = [\n",
    "    {\"name\": \"Current Trend\", \"remote_work_percent\": 30.0, \"is_weekend\": 0, \"is_holiday\": 0},\n",
    "    {\"name\": \"Return to Office\", \"remote_work_percent\": 15.0, \"is_weekend\": 0, \"is_holiday\": 0},\n",
    "    {\"name\": \"Fully Remote\", \"remote_work_percent\": 80.0, \"is_weekend\": 0, \"is_holiday\": 0},\n",
    "    {\"name\": \"Hybrid (3 days in office)\", \"remote_work_percent\": 40.0, \"is_weekend\": 0, \"is_holiday\": 0},\n",
    "    {\"name\": \"Weekend\", \"remote_work_percent\": 30.0, \"is_weekend\": 1, \"is_holiday\": 0},\n",
    "    {\"name\": \"Holiday\", \"remote_work_percent\": 30.0, \"is_weekend\": 0, \"is_holiday\": 1},\n",
    "]\n",
    "\n",
    "# Analyze scenarios\n",
    "scenario_results = remote_work_model.scenario_analysis(\n",
    "    X=X_test.iloc[:1],  # Use first test sample as baseline\n",
    "    scenario_configs=scenarios\n",
    ")\n",
    "\n",
    "# Plot scenario comparison\n",
    "remote_work_model.plot_scenario_comparison(scenario_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast ridership with changing remote work patterns\n",
    "forecast_data = remote_work_model.time_series_forecast(\n",
    "    X=X_test.iloc[:1],  # Use first test sample as baseline\n",
    "    steps=24,  # Forecast for 24 time periods\n",
    "    remote_work_trend=[30, 35, 40, 45, 50, 55, 60, 65, 70, 70, 70, 65,\n",
    "                        60, 55, 50, 45, 40, 35, 30, 30, 30, 35, 40, 45],  # Trend pattern\n",
    "    time_col=\"forecast_period\"\n",
    ")\n",
    "\n",
    "# Create historical data for plotting\n",
    "historical_data = route_data.iloc[-24:].copy().reset_index(drop=True)\n",
    "historical_data['forecast_period'] = range(len(historical_data))\n",
    "forecast_data['forecast_period'] = range(len(historical_data), len(historical_data) + len(forecast_data))\n",
    "\n",
    "# Plot forecast\n",
    "remote_work_model.plot_forecast(\n",
    "    historical_data=historical_data,\n",
    "    forecast_data=forecast_data,\n",
    "    time_col=\"forecast_period\",\n",
    "    value_col=\"ridership\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated the key functionality of the TransitVision package:\n",
    "\n",
    "1. Data processing for transit and feedback data\n",
    "2. Transit data analysis and visualization\n",
    "3. Sentiment analysis of rider feedback\n",
    "4. Ridership prediction using machine learning\n",
    "5. Remote work impact analysis and forecasting\n",
    "\n",
    "The TransitVision package provides a comprehensive set of tools for transit agencies to analyze their data and make informed decisions about service planning, customer satisfaction, and future ridership patterns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3] *",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
